{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BeamLSTM.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/keith-leung/cis667/blob/master/BeamLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dOr8brXpY8g"
      },
      "source": [
        "import torch as tr"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HEUqfugE63WD",
        "outputId": "7cf3cebc-d574-432c-8617-f5039d8ba52a"
      },
      "source": [
        "a = tr.tensor([-10, 10, 10])\n",
        "tr.exp(a) / tr.exp(a).sum()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([1.0306e-09, 5.0000e-01, 5.0000e-01])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6gzPOQGkpn7s"
      },
      "source": [
        "sentences = [\n",
        "  \"How are you\",\n",
        "  \"Who are you\",\n",
        "  \"Who are they\",\n",
        "  \"Who are we\",\n",
        "  \"Who am I\",\n",
        "  \"Who am I\",\n",
        "  \"Where are you going\"\n",
        "]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QacVbxD0qE8p",
        "outputId": "d22ae412-dd9b-4027-9530-53fe26b40714"
      },
      "source": [
        "# Make a dictionary mapping each word to a one-hot tensor\n",
        "words = set()\n",
        "for sentence in sentences:\n",
        "  for word in sentence.split(\" \"):\n",
        "    words.add(word)\n",
        "words = tuple(words) # deterministic order\n",
        "\n",
        "# PyTorch LSTM expects 3d tensors representing (sequence length, batch size, number of features)\n",
        "I = tr.eye(len(words))\n",
        "dictionary = {\n",
        "    word: I[w].reshape(1,1,len(words))\n",
        "    for w,word in enumerate(words)}\n",
        "\n",
        "print(dictionary)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'I': tensor([[[1., 0., 0., 0., 0., 0., 0., 0., 0., 0.]]]), 'am': tensor([[[0., 1., 0., 0., 0., 0., 0., 0., 0., 0.]]]), 'Where': tensor([[[0., 0., 1., 0., 0., 0., 0., 0., 0., 0.]]]), 'How': tensor([[[0., 0., 0., 1., 0., 0., 0., 0., 0., 0.]]]), 'they': tensor([[[0., 0., 0., 0., 1., 0., 0., 0., 0., 0.]]]), 'going': tensor([[[0., 0., 0., 0., 0., 1., 0., 0., 0., 0.]]]), 'Who': tensor([[[0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]]]), 'we': tensor([[[0., 0., 0., 0., 0., 0., 0., 1., 0., 0.]]]), 'are': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 1., 0.]]]), 'you': tensor([[[0., 0., 0., 0., 0., 0., 0., 0., 0., 1.]]])}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61EO3qfXq7LW",
        "outputId": "da37aaa3-3ca7-455d-aa75-150342d7be65"
      },
      "source": [
        "# Define a small LSTM recurrent neural network with linear hidden-to-output layer\n",
        "class Net(tr.nn.Module):\n",
        "  def __init__(self, hidden_size):\n",
        "    super(Net, self).__init__()\n",
        "    self.lstm = tr.nn.LSTM(input_size = len(words), hidden_size = hidden_size)\n",
        "    self.readout = tr.nn.Linear(in_features=hidden_size, out_features=len(words))\n",
        "  def forward(self, x, v=None):\n",
        "    _, v = self.lstm(x) if v is None else self.lstm(x, v) # update hidden from input\n",
        "    h, c = v # LSTM hidden vector and internal so-called \"cell state\"\n",
        "    y = self.readout(h) # get output from hidden\n",
        "    y = tr.softmax(y, dim=-1) # make sure output is a probability distribution\n",
        "    return y, v\n",
        "\n",
        "print(Net(3))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Net(\n",
            "  (lstm): LSTM(10, 3)\n",
            "  (readout): Linear(in_features=3, out_features=10, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12O8JsDZsj5W",
        "outputId": "11f86e70-02fd-4984-8e88-7731347a9b33"
      },
      "source": [
        "net = Net(3)\n",
        "opt = tr.optim.SGD(net.parameters(), lr=0.01)\n",
        "\n",
        "for epoch in range(2000):\n",
        "\n",
        "  batch_loss = 0.\n",
        "\n",
        "  for sentence in sentences:\n",
        "    tokens = sentence.split(\" \")\n",
        "\n",
        "    v = None # no hidden activation at first time-step\n",
        "    for t in range(len(tokens)-1):\n",
        "\n",
        "      y, v = net(dictionary[tokens[t]], v)\n",
        "      y_target = dictionary[tokens[t+1]]\n",
        "\n",
        "      #loss = tr.sum((y - y_target)**2) # MSE\n",
        "      loss = -tr.sum(y_target * tr.log(y)) # Cross-entropy\n",
        "      batch_loss += loss\n",
        "\n",
        "  batch_loss.backward()\n",
        "  opt.step()\n",
        "  opt.zero_grad()\n",
        "\n",
        "  if epoch % 100 == 0: print(epoch, batch_loss.item())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0 36.9460334777832\n",
            "100 27.079044342041016\n",
            "200 24.730289459228516\n",
            "300 20.0532283782959\n",
            "400 15.06004524230957\n",
            "500 12.627098083496094\n",
            "600 11.252155303955078\n",
            "700 10.191694259643555\n",
            "800 9.365312576293945\n",
            "900 8.77193832397461\n",
            "1000 8.351117134094238\n",
            "1100 8.044500350952148\n",
            "1200 7.815389633178711\n",
            "1300 7.6418280601501465\n",
            "1400 7.508695125579834\n",
            "1500 7.40455961227417\n",
            "1600 7.321336269378662\n",
            "1700 7.253550052642822\n",
            "1800 7.197437286376953\n",
            "1900 7.150343418121338\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4N5wYzzzwczj",
        "outputId": "aa5d570c-070a-405d-e91c-d69d8f9f2209"
      },
      "source": [
        "# Try predicting\n",
        "word = \"Who\"\n",
        "v = None\n",
        "print(word)\n",
        "\n",
        "for t in range(3):\n",
        "  x = dictionary[word]\n",
        "  y, v = net(dictionary[tokens[t]], v)\n",
        "  y = y.squeeze() # ignore singleton dimensions for time-step/example\n",
        "  w = y.argmax()\n",
        "  word = words[w]\n",
        "  prob = y[w]\n",
        "  print(word, prob.item())\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Who\n",
            "are 0.935569703578949\n",
            "you 0.9646154046058655\n",
            "going 0.9231652617454529\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZWhrttT1_CJN",
        "outputId": "9d6072fc-48cb-4c20-a3bc-efa3a6786c10"
      },
      "source": [
        "a=tr.arange(10).reshape((1,1,10)).squeeze()\n",
        "print(a)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AVc4ZmU_FgQ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}